\documentclass[a4paper]{article}

\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[colorinlistoftodos]{todonotes}

\title{CIS Programming Homework 1}
\author{Zachary Sabin and Joseph Min}

\begin{document}
\maketitle

\section{Mathematical Approaches and Algorithms}
\subsection{Point Cloud to Point Cloud Registration}
Our algorithm for solving point cloud to point cloud rigid body transformations is based on a method found in Horn's paper. Our algorithm accepts two sets of column vectors as inputs. It is assumed that the vector in column $n$ in the first point cloud represents the same point as column $n$ in the second point cloud. We then normalize these two point clouds by finding their respective centroids, then subtracting the values of the centroid from each of their points. This effectively moves both point clouds to be centered on the origin.

Once the point clouds are centered on the origin, we then attempt to find the rotation matrix that best fits the two point clouds together. The first step of this is to multiply the equivalent coordinates of respective points together and sum up those products. For example we take the product of every x$_i$ in the first point cloud and the x$_i$ in the second point cloud and then take the sum of these products (let us call this xx):
\[xx = \sum_{i}^{N}(C1x_i*C2x_i)\]
We then find yy, zz, xy, yz, zx, xz, yx, and zy, and use these values to compute a 4x4 matrix as outlined in Hornâ€™s paper$^1$:
\[
\begin{bmatrix}
    xx+yy+zz & yz-zy & zx-xz  & xy-yx \\
    yz-zy & xx-yy-zz & xy+yx & zx+xz \\
    zx-xz & xy+yx & yy-xx-zz & yz+zy \\
    xy-yz & zx+xz & yz+zy & zz-xx-yy
\end{bmatrix}
\]
We then find the eigen decomposition of this matrix. The eigenvector that corresponds to the largest eigenvalue is equivalent to the unit quaternion that represents the best fit rotation matrix. We can now use this unit quaternion to compute the rotation matrix for these two point clouds. The method to do this can be seen in the equation below. Where $q_i$ represents the $i^{th}$ element of the unit quaternion.

\[
\begin{bmatrix}
    q_1^2 + q_2^2 - q_3^2 - q_4^2 & 2*(q_2*q_3 - q_1*q_4) & 2*(q_2*q_4 + q_1*q_3)\\
    2*(q_2*q_3 + q_1*q_4) & q_1^2 - q_2^2 + q_3^2 - q_4^2 & 2*(q_3*q_4 - q_1*q_2)\\
    2*(q_2*q_4 - q_1*q_3) & 2*(q_3*q_4 + q_1*q_2) & q_1^2 - q_2^2 - q_3^2 + q_4^2 \\
\end{bmatrix}
\]
Once we have obtained the rotation matrix we now must compute the translation component of the frame transformation. In order to do this we got back to the original point clouds, before we shifted them to be centered on the origin. We apply the rotation matrix that we found to the non transformed points. We then find the difference in x,y, and z between the centroid of the rotated point cloud and the centroid of the fully transformed point cloud. The column vector of these differences represents the translation. We now have both the rotation and translation components of the frame transformation. 
\subsection{Pivot Calibration Method}
\subsubsection{Electromagnetic Pivot}

The first step in performing the pivot calibration is to determine the location of the markers in the coordinate system of the probe. In order to do this we take the first frame of input data, which represents the positions of the markers with respect to the EM tracker base coordinate system. We find the centroid of all of these points and define that as the origin of the probe coordinate system. We then define the marker coordinates with respect to this origin. These points are constant through all frames, since the location of the markers in the probe coordinate system will never change. 

Once we have determined the locations of the marker points relative to the probe, we then read in the frames, each of which represents the positions of the markers on the probe relative to the EM Tracker Base for a different pivot angle. For each frame we utilize our frame transformation method to calculate the rotation and translation that best fit the transformation of that frame from the EM Tracker Base coordinate system to the probe coordinate system. 

Once we have the frame transformation we can see that the following equation will hold, where $P_{dimple}$ represents the distance from the EM Tracker Base to the tip of the probe, $t_g$ represents the location of the tip of the probe with respect to the probe coordinate system, and $F_G = [R_G, p_G]$ represents the frame transform from the EM Tracker Base coordinate system to the probe coordinate system, and $t_g + P_{dimple}$ is actually a concatenation of matrices along the vertical axis.
\[ R_G * t_g + p_G = P_{dimple} \implies (R_G - I)(t_g + P_{dimple}) = t_g\]

By setting up this equation for each frame, we obtain a system of equations for the entire calibration. 

\[
\begin{bmatrix}
    \vdots & | & \vdots \\
    Rotations_i & | & -I \\
    \vdots & | & \vdots
\end{bmatrix}
\begin{bmatrix}
    t_g \\
    ----- \\
    P_{dimple}
\end{bmatrix}
 = 
\begin{bmatrix}
    \vdots \\
    -Translations_i \\
    \vdots
\end{bmatrix}
\]
We can then solve this system using a least squares approach. This will yield the optimal (in the least squares sense) results for $t_g$ and $P_{dimple}$. 
\subsubsection{Optical Pivot}
The optical pivot calibration assumes that the transform from the probe to the EM Tracker Base is constant but the transform from the optical tracker to both the probe and the EM Tracker Base may vary in each frame. Therefore we must transform the points that the optical tracker sees on the probe in each frame to be in the coordinate system of the EM Tracker Base. To do this we read in the optical markers coordinates in the EM Tracker system from a file. Using these points and the D data from the frame we can then calculate $F_D$ which transforms points from the EM Base coordinate system to the Optical coordinate system. We can now use the exact method as described in the electromagnetic pivot calibration, but for each frame we transform the points using $F_D^{-1}$ so that we have points in the coordinate system of the EM Tracker Base and in the probe's coordinate system. This creates a scenario that is identical to the EM Pivot Calibration. 

\section{Our Code}
Our code is split into three executable files named cloudregister.py, pivot\_cal.py, and opt\_pivot\_cal.py. As the extensions would suggest, these are all Python scripts. Each has our point cloud to point cloud registration method in it (which we call get\_frame()), as well as a Frame class (that has its rotation and translation components, representing a full frame transformation). Given more time, we would have extracted these into a separate class to make our code less repetitive and more object-oriented.

\subsection{Frame Class}
Our Frame class is a very simple class that holds a rotation matrix and a translation vector, which default to the identity matrix and the zero vector respectively. Its current methods are simply the setters and getters for each property.

\subsection{get\_frame()}
Our get\_frame() function follows the algorithm as outlined in 1.1. It takes in two point clouds as arguments, and then immediately stores one two copies of the arguments so we can manipulate the arguments and still have the original inputs. We first calculate the centroids of each point cloud by taking the sum of each coordinate in each cloud and then dividing by the number of points in each cloud (giving the mean of the points). The rest is a strict transcription of the algorithm into Python. The function returns an instance of the Frame class whose rotation and translation vectors are that of the frame transformation that transforms the first point cloud into the second.

\subsection{cloudregister.py}
Cloudregister.py is our solution to problem 4. It can be run from the command line by giving it two arguments, the calbody and cal\_readings text files respectively: \break
\begin{center}
python cloudregister.py /path/to/file/calbody.txt /path/to/file/calreadings.txt \break
\end{center}
It first parses through the calbody text file and stores the number of d, a, and c readings there will be in the file. It takes these and turns them each into the upper limits of for-loops that each get the data for each d, a, and c vector.
It then moves on to the calreadings file. It takes the data for how many frames that the calreadings text file has and uses this as the upper limit for an outer for-loop. Inside this loop, we take each of the D and A readings from the file like we did the d and a readings from the calbody loop. We now have two sets of point clouds: D/d and A/a. So, we now find what frame transformation turns D into d and A into a respectively by passing these point clouds as arguments to our get\_frame() function, and store these into an array of frame transformations for D/d and A/a.
We then calculate each of our expected C$_i$ values by taking the inverse of our A/a frame transformation and multiplying it by our D/d transformation and each of the c$_i$ values:
\[F_a^{-1}F_dc_i = C_i^{expected}\]
We then output these values to standard out, which we can pipe into a text file using normal commandline arguments as follows:
\begin{center}
python cloudregister.py /path/to/file/calbody.txt /path/to/file/calreadings.txt $>>$ /path/to/file/output.txt
\end{center}

\subsection{pivot\_cal.py}
Pivot\_cal.py is our solution to problem 5. It can be run from the command line by giving it just the empivot.txt file as an argument: \break
\begin{center}
python pivot\_cal.py /path/to/file/empivot.txt \break
\end{center}
In pivot\_cal.py we have the same get\_frame() method and Frame class to start us off. However, now we just read in the number of EM markers and the number of frames for which we have data. The number of frames is our limit for our outer loop, in which we get all the points for the point cloud G. If this is the first frame, we also calculate a centroid, G0, as well as the point cloud g with respect to the first probe coordinates by taking this first G and subtracting G0. We then, for every frame, calculate the frame transformation for G/g by passing these two arguments into our get\_frame(). We then store the rotation and translation components of each frame transformation separately in their respective arrays. By the end, each array holds every rotation and every translation components of every frame transformation.
Once we have all of our rotations and translations, we solve the system of equations as outlined in 1.2 by using the built-in numpy method, lstsq, for solving systems of equations. We then output these values to standard out.

\subsection{opt\_pivot\_cal.py}
Opt\_pivot\_cal.py is our solution to problem 6. It can be run from the command line by giving it the optpivot.txt file and calbody.txt file as arguments: \break
\begin{center}
python pivot\_cal.py /path/to/file/optpivot.txt /path/to/file/calbody.txt\break
\end{center}
Opt\_pivot\_cal.py has almost the exact same code as pivot\_cal.py, but instead of simply storing the rotations and translations from g to G, we have to find the overall transformation, $F_D^{-1}F_H$, which we do by taking in, again, the calbody file (which allows us to calculate F$_D$ as before), and the optpivot.txt file (which gives us D and H values, which allows us to calculate F$_H$ like we did F$_G$ in pivot\_cal.py.

\section{Debugging}
The first section of this code that we wrote was a method that generated a frame transformation given two point clouds. In order to test this method we first hand generated a few point clouds and their transformed versions in order to sanity check the code. We then wrote a unit test for this method that would randomly generate a point cloud, a rotation matrix, and a translation, and apply to the rotation and translation to the point cloud. It then checked the output of the frame transformation method given the two point clouds against the generated rotation and translation in order to ensure that the calculated transformation was correct. We also created a method that added noise to the generated point cloud in order to ensure that our frame transformation method would still function correctly in the presence of some error. 

In order to test our registration and pivot calibration algorithms we hand generated some sample data sets where we knew the correct output. We used these as sanity checks throughout the coding process to ensure that our code was making progress on these sets. Finally we debugged the two algorithms using the provided debugging data sets and ensured that our outputs matched the provided ones. 

\section{Who Dunnit?}
For this assignment we worked almost completely in pair programming. This would consist of one person coding and the other person looking over the shoulder to ensure correctness and offer guidance on the structure and flow of the code. We switched who was coding fairly frequently. However, we did split up some of the coding. Zach wrote the unit tests for and debugged the frame transformation method, while Joe handled the file i/o and formatting the output. In order to keep our code up to date with each other we used github and git as a versioning system. 

\end{document}